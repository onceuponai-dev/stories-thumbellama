# Thumbellama





```bash
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.1  --target webgpu --quantization q4f32_0 --use-safetensors
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.2  --target webgpu --quantization q4f32_0 --use-safetensors
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.3  --target webgpu --quantization q4f32_0 --use-safetensors
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.4  --target webgpu --quantization q4f32_0 --use-safetensors
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.5  --target webgpu --quantization q4f32_0 --use-safetensors
python3 -m mlc_llm.build --hf-path TinyLlama/TinyLlama-1.1B-Chat-v0.6  --target webgpu --quantization q4f32_0 --use-safetensors
```
